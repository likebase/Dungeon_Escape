{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b76e1c61-f31e-400e-9118-ed1a32aa4c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "녹음하시겠습니까? y/n y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "녹음 중... 1초 경과...\n",
      "녹음 중... 2초 경과...\n",
      "녹음 중... 3초 경과...\n",
      "녹음 중... 4초 경과...\n",
      "녹음 중... 5초 경과...\n",
      "녹음 중료\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'UnknownValueError' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m     audio \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mrecord(source, duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m)\n\u001b[1;32m---> 49\u001b[0m vToText \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mko_KR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(vToText)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\speech_recognition\\recognizers\\google.py:251\u001b[0m, in \u001b[0;36mrecognize_legacy\u001b[1;34m(recognizer, audio_data, key, language, pfilter, show_all, with_confidence)\u001b[0m\n\u001b[0;32m    248\u001b[0m output_parser \u001b[38;5;241m=\u001b[39m OutputParser(\n\u001b[0;32m    249\u001b[0m     show_all\u001b[38;5;241m=\u001b[39mshow_all, with_confidence\u001b[38;5;241m=\u001b[39mwith_confidence\n\u001b[0;32m    250\u001b[0m )\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\speech_recognition\\recognizers\\google.py:124\u001b[0m, in \u001b[0;36mOutputParser.parse\u001b[1;34m(self, response_text)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, response_text: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 124\u001b[0m     actual_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_all:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\speech_recognition\\recognizers\\google.py:173\u001b[0m, in \u001b[0;36mOutputParser.convert_to_result\u001b[1;34m(response_text)\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n",
      "\u001b[1;31mUnknownValueError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m         vToText \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mrecognize_google(audio_data\u001b[38;5;241m=\u001b[39maudio, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mko_KR\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;28mprint\u001b[39m(vToText)\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43mUnknownValueError\u001b[49m:\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m음성이 인식되지 않았습니다!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'UnknownValueError' is not defined"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import speech_recognition as sr\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 5\n",
    "WAVE_OUTPUT_FILENAME = 'output.wav'\n",
    "r = sr.Recognizer()\n",
    "p = pyaudio.PyAudio()\n",
    "i2 = 0\n",
    "\n",
    "e = input(\"녹음하시겠습니까? y/n\")\n",
    "\n",
    "if e == 'y':\n",
    "    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "        \n",
    "        e1 = i * CHUNK / RATE\n",
    "        \n",
    "        if (int(e1) == i2):\n",
    "            print(f'녹음 중... {int(e1+1)}초 경과...')\n",
    "            i2+=1\n",
    "\n",
    "    print('녹음 중료')\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    \n",
    "    with sr.AudioFile('output.wav') as source:\n",
    "        audio = r.record(source, duration=120)\n",
    "\n",
    "    vToText = r.recognize_google(audio_data=audio, language='ko_KR')\n",
    "    print(vToText)\n",
    "else:\n",
    "    print(\"프로그램을 종료합니다\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f218029-4a86-4786-a790-ba7a50e963a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
